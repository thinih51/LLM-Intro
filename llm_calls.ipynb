{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect and compare LLMs\n",
    "\n",
    "- Connect to the grok API and choose a model\n",
    "- Connect to the Gemini API and choose a model\n",
    "- Connect to the OpenAI API and choose 4o-mini\n",
    "\n",
    "### Create a prompt and inject a little text snippet of your liking\n",
    "- The LLM should use the injected information to answer a question.\n",
    "\n",
    "### Compare the outputs\n",
    "- Use the same method for every model.\n",
    "- Do you see differences?\n",
    "\n",
    "**Tipp:** for prompt injection you can either use string concatenation or the python String formatter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting groq\n",
      "  Downloading groq-0.23.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.167.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic (from google-generativeai)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting tqdm (from google-generativeai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tshed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai) (4.13.2)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.0rc0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting requests<3.0.0,>=2.18.0 (from google-api-core->google-generativeai)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google-generativeai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic->google-generativeai)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->google-generativeai)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tshed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.5/1.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "   ---------------------------------------- 0.0/661.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 661.2/661.2 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading groq-0.23.0-py3-none-any.whl (127 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading google_api_core-2.25.0rc0-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading google_api_python_client-2.167.0-py2.py3-none-any.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.2 MB 4.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/13.2 MB 4.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.9/13.2 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.2/13.2 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.2/13.2 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.6/13.2 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.6/13.2 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.9/13.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/13.2 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.0/13.2 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.3/13.2 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.1/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, uritemplate, typing-inspection, tqdm, sniffio, python-dotenv, pyparsing, pydantic-core, pyasn1, protobuf, jiter, idna, h11, grpcio, distro, charset-normalizer, certifi, cachetools, annotated-types, rsa, requests, pydantic, pyasn1-modules, proto-plus, httplib2, httpcore, googleapis-common-protos, dotenv, anyio, httpx, grpcio-status, google-auth, openai, groq, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 distro-1.9.0 dotenv-0.9.9 google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc0 google-api-python-client-2.167.0 google-auth-2.39.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 groq-0.23.0 grpcio-1.71.0 grpcio-status-1.71.0 h11-0.14.0 httpcore-1.0.8 httplib2-0.22.0 httpx-0.28.1 idna-3.10 jiter-0.9.0 openai-1.76.0 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.3 pydantic-core-2.33.1 pyparsing-3.2.3 python-dotenv-1.1.0 requests-2.32.3 rsa-4.9.1 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.0 uritemplate-4.1.1 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "%pip install google-generativeai openai groq dotenv\n",
    "\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Access the API key using the variable name defined in the .env file\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/quickstart?hl=de&lang=python\n",
    "examples: https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb?hl=de#scrollTo=WxiIfsbA0WdH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI works by learning patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=google_api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the twinkling stars, a gentle unicorn tiptoed through a moonlit meadow, spreading dreams of magic and wonder to all who slept nearby.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groq\n",
    "https://console.groq.com/docs/quickstart\n",
    "\n",
    "goal: llama-3.3-70b-versatile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's technological landscape, and their importance can be seen in several areas:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process and analyze vast amounts of text data quickly, making them ideal for applications where speed is essential, such as real-time chatbots, sentiment analysis, and language translation.\n",
      "2. **Improved User Experience**: Fast language models enable rapid response times, which is critical for providing a good user experience. Users expect quick and accurate results, and slow models can lead to frustration and abandonment.\n",
      "3. **Increased Productivity**: Fast language models can automate tasks such as data extraction, text summarization, and content generation, freeing up human resources for more complex and creative tasks.\n",
      "4. **Competitive Advantage**: Organizations that adopt fast language models can gain a competitive edge by responding quickly to customer inquiries, analyzing large datasets, and making data-driven decisions faster than their competitors.\n",
      "5. **Real-time Applications**: Fast language models are essential for real-time applications such as:\n",
      "\t* Sentiment analysis for social media monitoring\n",
      "\t* Chatbots for customer support\n",
      "\t* Language translation for international communication\n",
      "\t* Text summarization for news and media outlets\n",
      "6. **Scalability**: Fast language models can handle large volumes of data and scale to meet the needs of growing organizations, making them an essential tool for big data analytics and machine learning.\n",
      "7. **Cost Savings**: Fast language models can reduce the computational resources required for language processing tasks, leading to cost savings and increased efficiency.\n",
      "8. **Enhanced Security**: Fast language models can help detect and respond to security threats in real-time, such as identifying phishing emails or detecting malicious activity.\n",
      "9. **Improved Accuracy**: Fast language models can process large amounts of data, which can lead to improved accuracy in language understanding and generation tasks, such as speech recognition and language translation.\n",
      "10. **Future-Proofing**: Fast language models are essential for future applications such as voice assistants, autonomous vehicles, and smart homes, where rapid language processing is critical for safe and efficient operation.\n",
      "\n",
      "To achieve fast language models, several techniques are employed, including:\n",
      "\n",
      "1. **Model Pruning**: Removing redundant or unnecessary model parameters to reduce computational requirements.\n",
      "2. **Knowledge Distillation**: Transferring knowledge from large models to smaller, faster models.\n",
      "3. **Quantization**: Representing model parameters using fewer bits to reduce computational requirements.\n",
      "4. **Parallel Processing**: Using multiple processing units or GPUs to speed up model inference.\n",
      "5. **Efficient Architectures**: Designing models with efficient architectures that minimize computational requirements.\n",
      "\n",
      "By leveraging these techniques, fast language models can provide significant benefits in various applications, from customer service to data analysis, and play a critical role in shaping the future of artificial intelligence and natural language processing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(groq_api_key),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
